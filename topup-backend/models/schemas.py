"""
Pydantic schemas for Topup CXO Assistant.

This module defines the core data models used throughout the application:
- Plan: Structured query plan generated by the Planner Agent
- SegmentFilters: Filter criteria for data segmentation
- Insight: Narrative insights and variance analysis
- Driver: Segment-level performance drivers
"""

import hashlib
import json
from typing import List, Literal, Optional

from pydantic import BaseModel, Field


class SegmentFilters(BaseModel):
    """
    Segment filter criteria for data queries.
    
    Attributes:
        channel: Marketing channel (OMB, Email, Search, D2LC, DM, LT, Experian, Karma, Small Partners)
        grade: Credit grade (P1, P2, P3, P4, P5, P6)
        prod_type: Product type (Prime, NP, D2P)
        repeat_type: Customer type (Repeat, New)
        term: Loan term in months (36, 48, 60, 72, 84)
        cr_fico_band: FICO score band (<640, 640-699, 700-759, 760+)
        purpose: Loan purpose (debt_consolidation, home_improvement, major_purchase, medical, car, other)
    """
    channel: Optional[str] = None
    grade: Optional[str] = None
    prod_type: Optional[str] = None
    repeat_type: Optional[str] = None
    term: Optional[int] = None
    cr_fico_band: Optional[str] = None
    purpose: Optional[str] = None


class Plan(BaseModel):
    """
    Structured query plan generated by the Planner Agent.
    
    This model represents a validated query plan that will be executed
    by the SQL Agent. It includes all necessary information to generate
    the appropriate SQL query, chart visualization, and insights.
    
    Attributes:
        intent: Query intent classification
        table: Target database table
        metric: Metric to analyze (e.g., app_submit_amt, issued_amt)
        date_col: Date column for filtering
        window: Time window for analysis
        granularity: Aggregation granularity
        segments: Segment filters to apply
        chart: Chart type for visualization
    """
    intent: Literal[
        "trend",
        "variance",
        "forecast_vs_actual",
        "forecast_gap_analysis",
        "funnel",
        "distribution",
        "relationship",
        "multi_metric",
        "custom_query",
        "explain"
    ] = Field(..., description="Query intent classification")
    
    table: Literal["cps_tb", "forecast_df"] = Field(
        ...,
        description="Target database table"
    )
    
    metric: str = Field(
        ...,
        description="Metric to analyze (e.g., app_submit_amnt, apps_approved_amnt, issued_amnt, cr_fico, cr_dti, a_income)"
    )
    
    date_col: Literal[
        "app_create_d",
        "app_submit_d",
        "apps_approved_d",
        "issued_d",
        "date",
        "period"
    ] = Field(..., description="Date column for filtering")
    
    window: Literal[
        "last_7d",
        "last_full_week",
        "last_30d",
        "last_full_month",
        "last_3_full_months",
        "last_full_quarter",
        "last_full_year",
        "qtd",
        "mtd",
        "ytd",
        "custom",
        "context"
    ] = Field(..., description="Time window for analysis")
    
    granularity: Literal["daily", "weekly", "monthly"] = Field(
        ...,
        description="Aggregation granularity"
    )
    
    segments: SegmentFilters = Field(
        default_factory=SegmentFilters,
        description="Segment filters to apply"
    )
    
    chart: Literal[
        "line",
        "area",
        "bar",
        "grouped_bar",
        "funnel",
        "pie",
        "scatter",
        "waterfall",
        "none"
    ] = Field(..., description="Chart type for visualization")
    
    custom_sql: Optional[str] = Field(
        None,
        description="Custom LLM-generated SQL query for complex queries"
    )
    
    explanation: Optional[str] = Field(
        None,
        description="Explanation of what the query does"
    )
    
    def cache_key(self) -> str:
        """
        Generate a deterministic cache key from the plan.
        
        Uses SHA256 hash of the JSON representation to create a unique
        identifier for caching query results.
        
        Returns:
            str: Hexadecimal SHA256 hash of the plan JSON
        """
        plan_dict = self.model_dump()
        plan_json = json.dumps(plan_dict, sort_keys=True)
        return hashlib.sha256(plan_json.encode()).hexdigest()


class Driver(BaseModel):
    """
    Segment-level performance driver for variance analysis.
    
    Represents a specific segment's contribution to overall variance,
    including absolute and percentage changes.
    
    Attributes:
        segment: Segment identifier (e.g., "Channel: Email", "Grade: P1")
        value: Current period value
        delta: Absolute change from prior period
        delta_pct: Percentage change from prior period
    """
    segment: str = Field(..., description="Segment identifier")
    value: float = Field(..., description="Current period value")
    delta: float = Field(..., description="Absolute change from prior period")
    delta_pct: float = Field(..., description="Percentage change from prior period")


class Insight(BaseModel):
    """
    Narrative insights and variance analysis.
    
    Contains executive-level summary, key findings, and segment drivers
    generated by the Insights Agent.
    
    Attributes:
        title: Insight title
        summary: One-line executive takeaway
        bullets: 2-3 key findings as bullet points
        drivers: Top positive and negative segment drivers
    """
    title: str = Field(..., description="Insight title")
    summary: str = Field(..., description="One-line executive takeaway")
    bullets: List[str] = Field(
        default_factory=list,
        description="Key findings as bullet points (0-3 items)",
        max_length=3
    )
    drivers: List[Driver] = Field(
        default_factory=list,
        description="Top positive and negative segment drivers"
    )
